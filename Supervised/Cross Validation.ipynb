{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Model Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "import numpy as np\n",
    "import json\n",
    "import import_ipynb\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "%run Introduction.ipynb\n",
    "%run Background.ipynb\n",
    "%run Footnotes.ipynb\n",
    "%run Conclusion.ipynb\n",
    "\n",
    "%run Classification.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connection to mongoDB\n",
    "client = pymongo.MongoClient(\"127.0.0.1:27017\")\n",
    "\n",
    "db = client['IRsegmentationDB']\n",
    "pDataset = db['pDataset']\n",
    "bDataset = db['bDataset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [x['text'] for x in pDataset.find()][:170]\n",
    "annot = [x['annotations'] for x in pDataset.find()][:170]\n",
    "indexes = [x['doc'] for x in pDataset.find()][:170]\n",
    "\n",
    "train_size = 0.8\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def functional_segmenter(d, a):\n",
    "    # Instatiating Introduction Classifier\n",
    "    cIntro = IntroductionClassifier(d, a)\n",
    "    cIntro.train_test_split(random_state, train_size)\n",
    "    \n",
    "    cIntro.train()\n",
    "    cIntro.test()\n",
    "    \n",
    "    # Instantiating Background Classifier\n",
    "    cBackground = BackgroundClassifier(d, a)\n",
    "    cBackground.train_test_split(random_state, train_size)\n",
    "    cBackground.train()\n",
    "    cBackground.test()\n",
    "    \n",
    "    # Instatiating Footnotes Classifier\n",
    "    cFootnotes = FootnotesClassifier(d, a)\n",
    "    cFootnotes.train_test_split(random_state, train_size)\n",
    "    cFootnotes.train()\n",
    "    cFootnotes.test()\n",
    "    \n",
    "def conclusion_recognizer(d, a):\n",
    "    cConclusion = ConclusionRecognizer(d, a)\n",
    "    cConclusion.train_test_split(random_state, train_size)\n",
    "    cConclusion.train()\n",
    "    cConclusion.test()\n",
    "    \n",
    "def testing(d, a, i):\n",
    "    classifier = Classification(d, a, i)\n",
    "    classifier.set()\n",
    "    return classifier.get_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 10\n",
    "dim = (round(len(docs) / K))\n",
    "\n",
    "# Dividing in Folds\n",
    "data = []\n",
    "tmp = []\n",
    "for i in range(0, len(docs)):\n",
    "    tmp.append(i)\n",
    "    if(len(tmp) == dim or i == len(docs) - 1):\n",
    "        data.append(tmp)\n",
    "        tmp = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0  FOLD EVALUATION\n",
      "Start INTRODUCTION\n",
      "Start BACKGROUND\n",
      "Start FOOTNOTES\n",
      "Start CONCLUSIONS\n",
      "TESTING\n",
      "\n",
      " 1  FOLD EVALUATION\n",
      "Start INTRODUCTION\n",
      "Start BACKGROUND\n",
      "Start FOOTNOTES\n",
      "Start CONCLUSIONS\n",
      "TESTING\n",
      "\n",
      " 2  FOLD EVALUATION\n",
      "Start INTRODUCTION\n",
      "Start BACKGROUND\n",
      "Start FOOTNOTES\n",
      "Start CONCLUSIONS\n",
      "TESTING\n",
      "\n",
      " 3  FOLD EVALUATION\n",
      "Start INTRODUCTION\n",
      "Start BACKGROUND\n",
      "Start FOOTNOTES\n",
      "Start CONCLUSIONS\n",
      "TESTING\n",
      "\n",
      " 4  FOLD EVALUATION\n",
      "Start INTRODUCTION\n",
      "Start BACKGROUND\n",
      "Start FOOTNOTES\n",
      "Start CONCLUSIONS\n",
      "TESTING\n",
      "\n",
      " 5  FOLD EVALUATION\n",
      "Start INTRODUCTION\n",
      "Start BACKGROUND\n",
      "Start FOOTNOTES\n",
      "Start CONCLUSIONS\n",
      "TESTING\n",
      "\n",
      " 6  FOLD EVALUATION\n",
      "Start INTRODUCTION\n",
      "Start BACKGROUND\n",
      "Start FOOTNOTES\n",
      "Start CONCLUSIONS\n",
      "TESTING\n",
      "\n",
      " 7  FOLD EVALUATION\n",
      "Start INTRODUCTION\n",
      "Start BACKGROUND\n",
      "Start FOOTNOTES\n",
      "Start CONCLUSIONS\n",
      "TESTING\n",
      "\n",
      " 8  FOLD EVALUATION\n",
      "Start INTRODUCTION\n",
      "Start BACKGROUND\n",
      "Start FOOTNOTES\n",
      "Start CONCLUSIONS\n",
      "TESTING\n",
      "\n",
      " 9  FOLD EVALUATION\n",
      "Start INTRODUCTION\n",
      "Start BACKGROUND\n",
      "Start FOOTNOTES\n",
      "Start CONCLUSIONS\n",
      "TESTING\n"
     ]
    }
   ],
   "source": [
    "res = []\n",
    "\n",
    "for i in range(0, len(data)):\n",
    "    train_t = [x for j, x in enumerate(data) if j != i]\n",
    "    train = []\n",
    "    \n",
    "    for x in train_t:\n",
    "        train.extend(x)\n",
    "        \n",
    "    docs_cv = [docs[x] for x in train]\n",
    "    annot_cv = [annot[x] for x in train]\n",
    "    indexes_cv = [indexes[x] for x in train]\n",
    "    \n",
    "    print(\"\\n\", str(i), \" FOLD EVALUATION\")\n",
    "    \n",
    "    functional_segmenter(docs_cv, annot_cv)\n",
    "    conclusion_recognizer(docs_cv, annot_cv)\n",
    "    \n",
    "    test = data[i]\n",
    "    docs_test_cv = [docs[x] for x in test]\n",
    "    annot_test_cv = [annot[x] for x in test]\n",
    "    indexes_test_cv = [indexes[x] for x in test]\n",
    "    \n",
    "    print(\"TESTING\")\n",
    "    res.append(testing(docs_test_cv, annot_test_cv, indexes_test_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([x['accuracy'] for x in res]) / len(res)\n",
    "\n",
    "K = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CV Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"Introduction\": {\n",
      "        \"P\": 1.0,\n",
      "        \"R\": 1.0,\n",
      "        \"F1\": 1.0\n",
      "    },\n",
      "    \"Background\": {\n",
      "        \"P\": 0.9588578088578089,\n",
      "        \"R\": 0.5834558823529413,\n",
      "        \"F1\": 0.7192845542253096\n",
      "    },\n",
      "    \"Analysis\": {\n",
      "        \"P\": 0.8511421795411568,\n",
      "        \"R\": 0.9470352561979279,\n",
      "        \"F1\": 0.8957136614279431\n",
      "    },\n",
      "    \"Conclusion\": {\n",
      "        \"P\": 0.9405076560615504,\n",
      "        \"R\": 0.9127157137401009,\n",
      "        \"F1\": 0.9254208350706223\n",
      "    },\n",
      "    \"Footnotes\": {\n",
      "        \"P\": 0.990909090909091,\n",
      "        \"R\": 0.9467088467088466,\n",
      "        \"F1\": 0.9662838827838829\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "stats = {\n",
    "    \"Introduction\": {\"P\": 0, \"R\": 0, \"F1\": 0},\n",
    "    \"Background\": {\"P\": 0, \"R\": 0, \"F1\": 0},\n",
    "    \"Analysis\": {\"P\": 0, \"R\": 0, \"F1\": 0},\n",
    "    \"Conclusion\": {\"P\": 0, \"R\": 0, \"F1\": 0},\n",
    "    \"Footnotes\": {\"P\": 0, \"R\": 0, \"F1\": 0}\n",
    "}\n",
    "\n",
    "for r in res:\n",
    "    stats['Introduction']['P'] += r['Introduction']['precision']\n",
    "    stats['Background']['P'] += r['Background']['precision']\n",
    "    stats['Analysis']['P'] += r['Analysis']['precision']\n",
    "    stats['Conclusion']['P'] += r['Conclusions']['precision']\n",
    "    stats['Footnotes']['P'] += r['Footnotes']['precision']\n",
    "    \n",
    "    stats['Introduction']['R'] += r['Introduction']['recall']\n",
    "    stats['Background']['R'] += r['Background']['recall']\n",
    "    stats['Analysis']['R'] += r['Analysis']['recall']\n",
    "    stats['Conclusion']['R'] += r['Conclusions']['recall']\n",
    "    stats['Footnotes']['R'] += r['Footnotes']['recall']\n",
    "    \n",
    "    stats['Introduction']['F1'] += r['Introduction']['f1-score']\n",
    "    stats['Background']['F1'] += r['Background']['f1-score']\n",
    "    stats['Analysis']['F1'] += r['Analysis']['f1-score']\n",
    "    stats['Conclusion']['F1'] += r['Conclusions']['f1-score']\n",
    "    stats['Footnotes']['F1'] += r['Footnotes']['f1-score']\n",
    "\n",
    "stats['Introduction']['P'] /= K\n",
    "stats['Background']['P'] /= K\n",
    "stats['Analysis']['P'] /= K\n",
    "stats['Conclusion']['P'] /= K\n",
    "stats['Footnotes']['P'] /= K\n",
    "\n",
    "stats['Introduction']['R'] /= K\n",
    "stats['Background']['R'] /= K\n",
    "stats['Analysis']['R'] /= K\n",
    "stats['Conclusion']['R'] /= K\n",
    "stats['Footnotes']['R'] /= K\n",
    "\n",
    "stats['Introduction']['F1'] /= K\n",
    "stats['Background']['F1'] /= K\n",
    "stats['Analysis']['F1'] /= K\n",
    "stats['Conclusion']['F1'] /= K\n",
    "stats['Footnotes']['F1'] /= K\n",
    "\n",
    "print(json.dumps(stats, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'./eval/CV01.p', 'wb') as handle:\n",
    "        pickle.dump(stats, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
