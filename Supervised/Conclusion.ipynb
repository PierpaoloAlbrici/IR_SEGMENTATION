{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import pycrfsuite\n",
    "import numpy as np\n",
    "\n",
    "%run FeatureExtraction.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConclusionRecognizer:\n",
    "    def __init__(self, docs, annots):\n",
    "        self.docs = docs\n",
    "        self.annot = annots\n",
    "        \n",
    "        self.filtering()\n",
    "        \n",
    "        print(\"Start CONCLUSIONS\")\n",
    "        \n",
    "    def filtering(self):\n",
    "         for i, (doc, annot) in enumerate(zip(self.docs, self.annot)):\n",
    "            nX, nL = [], []\n",
    "            for(p, a) in zip(doc, annot):\n",
    "                if(a['type'] == \"Analysis\" or a['type'] == \"Conclusions\"):\n",
    "                    nX.append(p)\n",
    "                    nL.append(a)\n",
    "            \n",
    "            self.docs[i] = nX\n",
    "            self.annot[i] = nL\n",
    "            \n",
    "    def train_test_split(self, rs, p):\n",
    "        X = [self.compute_feature_vector(i, doc) for i, doc in enumerate(self.docs)]\n",
    "        y = [self.get_label(i, doc) for i, doc in enumerate(self.docs)]\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = \\\n",
    "            train_test_split(X, y, train_size = p, random_state = rs)\n",
    "                             \n",
    "    def compute_feature_vector(self, i, doc):\n",
    "        fv = FeatureExtraction(doc, i, self.annot[i])\n",
    "        return fv.get_feature_vector_for_sentences()\n",
    "    \n",
    "    def get_label(self, i, d): \n",
    "        label = []\n",
    "\n",
    "        ls = []\n",
    "        for (p, a) in zip(d, self.annot[i]):\n",
    "            l = None\n",
    "\n",
    "            if(a['type'] == \"Analysis\"):\n",
    "                l = \"1\"\n",
    "            else: \n",
    "                l = \"0\"\n",
    "\n",
    "            for s in p:\n",
    "                ls.append(l)\n",
    "\n",
    "        return ls\n",
    "\n",
    "    def train(self):\n",
    "        trainer = pycrfsuite.Trainer(verbose=False)\n",
    "\n",
    "        #Submit training data to the trainer\n",
    "        for xseq, yseq in zip(self.X_train, self.y_train):\n",
    "            trainer.append(xseq, yseq)\n",
    "\n",
    "        # Set the parameters of the model\n",
    "        trainer.set_params({\n",
    "             #coefficient for L1 penality\n",
    "            \"c1\": 0.1, \n",
    "\n",
    "            #coefficient for L2 penality\n",
    "            \"c2\": 0.01, \n",
    "\n",
    "            # maximum number of iterations\n",
    "            \"max_iterations\": 200, \n",
    "\n",
    "            # whether to include transitions that \n",
    "            # are possibile, but not observed\n",
    "            \"feature.possible_transitions\": True\n",
    "        })\n",
    "\n",
    "        # Provide a file name as a paramter to the train function, such that \n",
    "        # the model will be saved to the file when training is finished\n",
    "        trainer.train(\"./Models/conclusion.model\")\n",
    "        \n",
    "    def test(self):\n",
    "        tagger = pycrfsuite.Tagger()\n",
    "        tagger.open(\"./Models/conclusion.model\")\n",
    "        y_pred = [tagger.tag(xseq) for xseq in self.X_test]\n",
    "        \n",
    "        # Create a mapping o la belas to indices\n",
    "        labels = {\"1\": 1, \"0\": 0}\n",
    "\n",
    "        # Convert the sequences of tags into a 1 dimensional array\n",
    "        predictions = np.array([labels[tag] for row in y_pred for tag in row])\n",
    "        truths = np.array([labels[tag] for row in self.y_test for tag in row])\n",
    "        # Print out the classification report\n",
    "        a = (classification_report(\n",
    "            truths, predictions, \n",
    "            target_names = [\"Conclusions\", \"Analysis\"],\n",
    "            output_dict=True\n",
    "        ))\n",
    "\n",
    "        return a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
