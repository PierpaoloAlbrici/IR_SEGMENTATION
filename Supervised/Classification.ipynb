{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from operator import itemgetter\n",
    "\n",
    "%run FeatureExtraction.ipynb   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class functionalPartAnalyzer:\n",
    "    def __init__(self, doc, fv, idx, annot):\n",
    "        self.doc = doc\n",
    "        self.annot = annot\n",
    "        self.fv = fv\n",
    "        self.index = idx\n",
    "        self.ffv = []\n",
    "        self.classification = []\n",
    "    \n",
    "    def introduction(self):\n",
    "        self.ffv = []\n",
    "        \n",
    "        tagger = pycrfsuite.Tagger()\n",
    "        tagger.open(\"./Models/intro.model\")\n",
    "        \n",
    "        y_pred = tagger.tag(self.fv)\n",
    "        \n",
    "        # Labeling\n",
    "        for i, (y, fv) in enumerate(zip(y_pred, self.fv)):\n",
    "            if(y == \"1\"):\n",
    "                self.classification.append({\n",
    "                    \"doc\": self.index,\n",
    "                    \"index\": int(fv[1].split(\"=\")[1]),\n",
    "                    \"label\": \"Introduction\"\n",
    "                })\n",
    "            else: \n",
    "                self.ffv.append(fv)\n",
    "                \n",
    "    def background(self):\n",
    "        tagger = pycrfsuite.Tagger()\n",
    "        tagger.open(\"./Models/background.model\")\n",
    "        \n",
    "        y_pred = tagger.tag(self.ffv)\n",
    "        \n",
    "        # Labeling\n",
    "        tffv = []\n",
    "        for i, (y, fv) in enumerate(zip(y_pred, self.ffv)):\n",
    "            if(y == \"1\"):\n",
    "                self.classification.append({\n",
    "                    \"doc\": self.index, \n",
    "                    \"index\": int(fv[1].split(\"=\")[1]),\n",
    "                    \"label\": \"Background\"\n",
    "                })\n",
    "            else: \n",
    "                tffv.append(fv)\n",
    "        self.ffv = tffv\n",
    "                \n",
    "    def footnotes(self):\n",
    "        tagger = pycrfsuite.Tagger()\n",
    "        tagger.open(\"./Models/footnotes.model\")\n",
    "        \n",
    "        y_pred = tagger.tag(self.ffv)\n",
    "        \n",
    "        # Labeling\n",
    "        tffv = []\n",
    "        for i, (y, fv) in enumerate(zip(y_pred, self.ffv)):\n",
    "            if(y == \"1\"):\n",
    "                self.classification.append({\n",
    "                    \"doc\": self.index,\n",
    "                    \"index\": int(fv[1].split(\"=\")[1]), \n",
    "                    \"label\": \"Footnotes\"\n",
    "                })\n",
    "            else: \n",
    "                tffv.append(fv)\n",
    "            \n",
    "        self.ffv = tffv\n",
    "        \n",
    "    def getClassification(self):\n",
    "        return self.classification\n",
    "        \n",
    "    def getFilteredFeatureVector(self):\n",
    "        return self.ffv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class conclusionRecognizer:\n",
    "    def __init__(self, p, ip, fv, idx):\n",
    "        self.paragraph = p\n",
    "        self.iParagraph = ip\n",
    "        self.index = idx\n",
    "        self.fv = fv\n",
    "        self.classification = None\n",
    "        \n",
    "    def recognizer(self): \n",
    "        tagger = pycrfsuite.Tagger()\n",
    "        tagger.open(\"./Models/conclusion.model\")\n",
    "        y_pred = tagger.tag(self.fv) \n",
    "        \n",
    "        if(sum([int(y) for y in y_pred]) > (len(y_pred) / 2)):\n",
    "            self.classification = {\n",
    "                \"doc\": self.index,\n",
    "                \"index\": int(self.iParagraph),\n",
    "                \"label\": \"Analysis\"\n",
    "            }\n",
    "        else:\n",
    "            self.classification = {\n",
    "                \"doc\": self.index,\n",
    "                \"index\": int(self.iParagraph),\n",
    "                \"label\": \"Conclusions\"\n",
    "            }\n",
    "            \n",
    "        return self.classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classification:\n",
    "    def __init__(self, docs, annots, indexes):\n",
    "        self.docs = docs\n",
    "        self.annot = annots\n",
    "        self.idxs = indexes\n",
    "        self.res = []\n",
    "        \n",
    "    def run(self, i, idx):\n",
    "        res = []\n",
    "        \n",
    "        #Extract feature vector\n",
    "        fx = FeatureExtraction(self.docs[i], idx, self.annot[i])\n",
    "        fv = fx.get_feature_vector()\n",
    "    \n",
    "        # Functional Part Analyzer\n",
    "        fpa = functionalPartAnalyzer(self.docs[i], fv, idx, self.annot[i])\n",
    "        fpa.introduction()\n",
    "        fpa.background()\n",
    "        fpa.footnotes()\n",
    "\n",
    "        res = fpa.getClassification()\n",
    "\n",
    "        # Conclusion Recognizer\n",
    "        # get paragraph's index that are still not classified \n",
    "        # it comes from annots index position\n",
    "        gff = fpa.getFilteredFeatureVector()\n",
    "        idxs = [(x[1].split(\"=\"))[1] for x in gff]\n",
    "        \n",
    "        #1 Analysis / 0 conclusions\n",
    "        for x in idxs: \n",
    "            pfv = fx.get_feature_vector_for_sentence(x)\n",
    "            cr = conclusionRecognizer(self.docs[i][int(x)], x, pfv, idx)\n",
    "            res.append(cr.recognizer())\n",
    "\n",
    "        res = sorted(res, key=lambda d: d['index']) \n",
    "            \n",
    "        return res\n",
    "    \n",
    "    def set(self):\n",
    "        for i, d in enumerate(self.docs):\n",
    "            r = self.run(i, self.idxs[i])\n",
    "            self.res.append(r)\n",
    "            \n",
    "    def get_results(self):\n",
    "        y_true = []\n",
    "        for x in self.annot:\n",
    "            for y in x:\n",
    "                y_true.append(y['type'])\n",
    "\n",
    "        y_true = np.array(y_true)\n",
    "        \n",
    "        y_pred = []\n",
    "        \n",
    "        ord_res = [sorted(self.res[x], key=itemgetter('index')) for x in range(0, len(self.res))] \n",
    "        for x in ord_res:\n",
    "            for y in x:\n",
    "                y_pred.append(y['label'])\n",
    "        \n",
    "        y_pred = np.array(y_pred)\n",
    "        # Print out the classification report\n",
    "        a = (classification_report(\n",
    "            y_true, y_pred, \n",
    "            labels = [\"Introduction\", \"Background\", \"Analysis\", \"Conclusions\", \"Footnotes\"], \n",
    "            output_dict=True\n",
    "        ))\n",
    "        \n",
    "        return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
